# langgraph_poc.py - Enhanced Knowledge Graph Power Demo

import streamlit as st
import pandas as pd
from docx import Document
import json
import base64
import re
import requests
from langgraph.graph import StateGraph, END
from typing import TypedDict
from pyvis.network import Network
import tempfile
import os
import streamlit.components.v1 as components
from collections import defaultdict, Counter
import networkx as nx

# =======================
# üîß LLM CONFIG
# =======================
LLM_API_URL = "https://your-llm-endpoint.com/v1/chat/completions"
LLM_USERNAME = "your_username_here"
LLM_PASSWORD = "your_password_here"

def get_basic_auth():
    creds = f"{LLM_USERNAME}:{LLM_PASSWORD}"
    return base64.b64encode(creds.encode()).decode()

# =======================
# üìÑ TEXT EXTRACTORS
# =======================
def extract_text_from_file(file):
    try:
        if file.name.endswith(".xlsx"):
            df = pd.read_excel(file)
            return df.to_csv(index=False)
        elif file.name.endswith(".docx"):
            doc = Document(file)
            return "\n".join([p.text for p in doc.paragraphs if p.text.strip()])
        elif file.name.endswith(".csv"):
            df = pd.read_csv(file)
            return df.to_csv(index=False)
    except Exception as e:
        return f"Error reading file: {e}"
    return ""

# =======================
# üéØ STRATEGIC GRAPH ANALYZER
# =======================
class StrategicGraphAnalyzer:
    def __init__(self, nodes, edges):
        self.nodes = {n['id']: n for n in nodes}
        self.edges = edges
        self.graph = nx.DiGraph()
        
        # Build NetworkX graph for analysis
        for node in nodes:
            self.graph.add_node(node['id'], **node)
        for edge in edges:
            self.graph.add_edge(edge['source'], edge['target'], **edge)
    
    def analyze_strategic_insights(self):
        insights = []
        
        # 1. Critical Components (High Connectivity)
        connectivity = dict(self.graph.degree())
        critical_threshold = max(3, int(len(self.nodes) * 0.1))  # Top 10% or min 3 connections
        critical_nodes = [(node, count) for node, count in connectivity.items() if count >= critical_threshold]
        
        if critical_nodes:
            critical_names = [node for node, _ in sorted(critical_nodes, key=lambda x: x[1], reverse=True)[:3]]
            insights.append({
                'type': 'critical',
                'title': 'üî¥ Critical Components (High Risk)',
                'content': f"These components have the most connections and could cause cascading failures: {', '.join(critical_names)}",
                'details': critical_nodes
            })
        
        # 2. Single Points of Failure
        spof_nodes = []
        for node in self.nodes:
            # Check if removing this node would disconnect the graph
            temp_graph = self.graph.copy()
            temp_graph.remove_node(node)
            if not nx.is_weakly_connected(temp_graph) and len(temp_graph.nodes()) > 1:
                spof_nodes.append(node)
        
        if spof_nodes:
            insights.append({
                'type': 'risk',
                'title': '‚ö†Ô∏è Single Points of Failure',
                'content': f"These components could disconnect the system if they fail: {', '.join(spof_nodes[:3])}",
                'details': spof_nodes
            })
        
        # 3. Management Gaps
        managed_components = set()
        managers = set()
        for edge in self.edges:
            if edge['type'] == 'MANAGES':
                managed_components.add(edge['target'])
                managers.add(edge['source'])
        
        unmanaged = [node for node in self.nodes.keys() 
                    if node not in managed_components and self.nodes[node]['type'] != 'Person']
        
        if unmanaged:
            insights.append({
                'type': 'governance',
                'title': 'üë• Management Gaps',
                'content': f"{len(unmanaged)} components lack clear ownership: {', '.join(unmanaged[:3])}",
                'details': unmanaged
            })
        
        # 4. Technology Concentration
        tech_usage = defaultdict(list)
        for edge in self.edges:
            if edge['type'] in ['USES', 'RUNS_ON']:
                tech_usage[edge['target']].append(edge['source'])
        
        concentrated_tech = [(tech, users) for tech, users in tech_usage.items() if len(users) > 2]
        if concentrated_tech:
            top_tech = sorted(concentrated_tech, key=lambda x: len(x[1]), reverse=True)[0]
            insights.append({
                'type': 'optimization',
                'title': 'üõ†Ô∏è Technology Concentration',
                'content': f"High dependency on {top_tech[0]} - used by {len(top_tech[1])} systems",
                'details': concentrated_tech
            })
        
        # 5. Network Density Analysis
        possible_edges = len(self.nodes) * (len(self.nodes) - 1)
        density = len(self.edges) / possible_edges * 100 if possible_edges > 0 else 0
        
        if density < 10:
            insights.append({
                'type': 'connectivity',
                'title': 'üìä Low Network Density',
                'content': f"Network is {density:.1f}% connected - many isolated components",
                'details': {'density': density}
            })
        elif density > 40:
            insights.append({
                'type': 'connectivity',
                'title': 'üåê High Network Density',
                'content': f"Network is {density:.1f}% connected - highly interdependent system",
                'details': {'density': density}
            })
        
        return insights
    
    def get_node_criticality_scores(self):
        """Calculate criticality score for each node"""
        scores = {}
        connectivity = dict(self.graph.degree())
        
        for node_id in self.nodes:
            score = 0
            
            # Connectivity score (30%)
            score += connectivity.get(node_id, 0) * 0.3
            
            # Centrality score (40%)
            try:
                centrality = nx.betweenness_centrality(self.graph)
                score += centrality.get(node_id, 0) * 40
            except:
                pass
            
            # Type importance (30%)
            node_type = self.nodes[node_id]['type']
            type_weights = {
                'Database': 1.0,
                'Application': 0.8,
                'Server': 0.7,
                'Person': 0.6,
                'Location': 0.3
            }
            score += type_weights.get(node_type, 0.5) * 0.3
            
            scores[node_id] = min(score, 1.0)  # Normalize to 0-1
        
        return scores

# =======================
# ü§ñ ENHANCED LLM FUNCTIONS
# =======================
def llm_extract_graph(text, structured_summary=""):
    if LLM_USERNAME == "your_username_here":
        return create_demo_graph()
    
    # Enhanced prompt specifically for business systems data
    prompt = f"""You are analyzing business systems data. Extract ALL actual system names, owners, and technologies from this data.

{structured_summary}

CRITICAL INSTRUCTIONS:
1. Use EXACT system names from the data (like "Risk Management System", "Customer Relationship Management")
2. Use EXACT owner names (like "John Smith", "Jane Doe")
3. Use EXACT technology names (like "Oracle", "MySQL", "Linux")
4. Use EXACT locations (like "Windows", "SQ", "SQL Server")
5. Create relationships based on data patterns:
   - Owner MANAGES System
   - System USES Technology
   - System LOCATED_IN Location
   - Systems with same owner/tech/location are RELATED

RETURN ONLY JSON with ACTUAL names from the data:
{{"nodes": [{{"id": "EXACT_SYSTEM_NAME", "type": "Application"}}, {{"id": "EXACT_OWNER_NAME", "type": "Person"}}], "edges": [{{"source": "EXACT_OWNER", "target": "EXACT_SYSTEM", "type": "MANAGES"}}]}}

JSON:"""
    
    try:
        headers = {"Authorization": f"Basic {get_basic_auth()}", "Content-Type": "application/json"}
        payload = {"inputs": prompt, "parameters": {"temperature": 0.05, "max_new_tokens": 1000}}
        
        response = requests.post(LLM_API_URL, headers=headers, json=payload, timeout=60)
        
        if response.status_code == 200:
            resp_json = response.json()
            
            if "generated_text" in resp_json:
                content = resp_json["generated_text"]
            elif isinstance(resp_json, list):
                content = resp_json[0].get("generated_text", str(resp_json))
            else:
                content = str(resp_json)
            
            st.write("**üîç LLM Processing Result:**")
            st.code(content[:800])
            
            # Extract JSON
            extracted_json = extract_json_multiple_ways(content)
            
            if extracted_json and len(extracted_json.get('nodes', [])) > 3:
                st.success(f"‚úÖ Extracted {len(extracted_json['nodes'])} nodes, {len(extracted_json['edges'])} edges")
                return extracted_json
            else:
                st.warning("‚ö†Ô∏è LLM didn't extract enough entities, creating from raw data")
                return create_rich_fallback_from_csv(structured_summary)
        else:
            st.error(f"LLM API error: {response.status_code}")
            return create_rich_fallback_from_csv(structured_summary)
            
    except Exception as e:
        st.error(f"LLM call failed: {e}")
        return create_rich_fallback_from_csv(structured_summary)

def create_rich_fallback_from_csv(structured_summary):
    """Create rich knowledge graph directly from CSV data"""
    st.write("**üõ†Ô∏è Creating knowledge graph from your actual data...**")
    
    nodes = []
    edges = []
    
    if "SAMPLE DATA ROWS:" in structured_summary:
        # Parse the structured summary
        lines = structured_summary.split('\n')
        data_rows = []
        
        for line in lines:
            if line.startswith("Row") and ":" in line:
                try:
                    # Extract the row data
                    row_str = line.split(": ", 1)[1]
                    row_data = eval(row_str)  # Convert string dict to actual dict
                    data_rows.append(row_data)
                except:
                    continue
        
        st.write(f"**üìä Processing {len(data_rows)} data rows...**")
        
        # Extract entities from actual data
        systems = set()
        owners = set()
        technologies = set()
        locations = set()
        
        for row in data_rows:
            for key, value in row.items():
                if value and value.strip():
                    key_lower = key.lower()
                    
                    # Identify system names
                    if any(word in key_lower for word in ['system', 'application', 'service', 'management']):
                        systems.add(value.strip())
                    
                    # Identify owners
                    elif any(word in key_lower for word in ['owner', 'responsible', 'manager']):
                        owners.add(value.strip())
                    
                    # Identify technologies
                    elif any(word in key_lower for word in ['technology', 'database', 'tech', 'platform']):
                        if value.strip().lower() in ['oracle', 'mysql', 'linux', 'windows', 'sql server', 'java', 'python']:
                            technologies.add(value.strip())
                    
                    # Identify locations
                    elif any(word in key_lower for word in ['location', 'site', 'environment', 'datacenter']):
                        locations.add(value.strip())
        
        # Create nodes
        for system in list(systems)[:20]:  # Limit to prevent overwhelming
            nodes.append({"id": system, "type": "Application"})
        
        for owner in list(owners)[:10]:
            nodes.append({"id": owner, "type": "Person"})
        
        for tech in list(technologies)[:10]:
            nodes.append({"id": tech, "type": "Technology"})
        
        for location in list(locations)[:10]:
            nodes.append({"id": location, "type": "Location"})
        
        # Create relationships based on data patterns
        for row in data_rows:
            row_system = None
            row_owner = None
            row_tech = None
            row_location = None
            
            # Find entities in this row
            for key, value in row.items():
                if value and value.strip():
                    key_lower = key.lower()
                    
                    if any(word in key_lower for word in ['system', 'application', 'service', 'management']):
                        row_system = value.strip()
                    elif any(word in key_lower for word in ['owner', 'responsible', 'manager']):
                        row_owner = value.strip()
                    elif any(word in key_lower for word in ['technology', 'database', 'tech', 'platform']):
                        if value.strip().lower() in ['oracle', 'mysql', 'linux', 'windows', 'sql server', 'java', 'python']:
                            row_tech = value.strip()
                    elif any(word in key_lower for word in ['location', 'site', 'environment', 'datacenter']):
                        row_location = value.strip()
            
            # Create relationships
            if row_owner and row_system:
                edges.append({"source": row_owner, "target": row_system, "type": "MANAGES"})
            
            if row_system and row_tech:
                edges.append({"source": row_system, "target": row_tech, "type": "USES"})
            
            if row_system and row_location:
                edges.append({"source": row_system, "target": row_location, "type": "LOCATED_IN"})
        
        # Add some interconnections for systems with same owner/tech
        owner_systems = defaultdict(list)
        tech_systems = defaultdict(list)
        
        for edge in edges:
            if edge['type'] == 'MANAGES':
                owner_systems[edge['source']].append(edge['target'])
            elif edge['type'] == 'USES':
                tech_systems[edge['target']].append(edge['source'])
        
        # Connect systems with same owner
        for owner, systems in owner_systems.items():
            for i in range(len(systems)):
                for j in range(i+1, len(systems)):
                    edges.append({
                        "source": systems[i],
                        "target": systems[j],
                        "type": "SHARED_OWNER"
                    })
        
        # Connect systems using same technology
        for tech, systems in tech_systems.items():
            for i in range(len(systems)):
                for j in range(i+1, len(systems)):
                    edges.append({
                        "source": systems[i],
                        "target": systems[j],
                        "type": "SHARED_TECHNOLOGY"
                    })
        
        st.success(f"‚úÖ Created graph with {len(nodes)} nodes and {len(edges)} edges from your actual data!")
        return {"nodes": nodes, "edges": edges}
    
    else:
        # Fallback to demo data
        st.warning("‚ö†Ô∏è Could not parse structured data, using demo graph")
        return create_demo_graph()

def enhance_graph_connectivity(graph_data, structured_summary):
    """Enhance graph connectivity based on data patterns"""
    nodes = graph_data.get('nodes', [])
    edges = graph_data.get('edges', [])
    
    # Create additional edges for shared resources
    node_attributes = {}
    
    # Parse structured summary to find shared attributes
    if structured_summary and "Row" in structured_summary:
        lines = structured_summary.split('\n')
        for line in lines:
            if line.startswith("Row"):
                try:
                    row_data = eval(line.split(": ")[1])
                    for key, value in row_data.items():
                        if key.lower() in ['owner', 'manager', 'location', 'database', 'technology']:
                            if value not in node_attributes:
                                node_attributes[value] = []
                            node_attributes[value].append(key)
                except:
                    continue
    
    # Add shared resource relationships
    for resource, usage in node_attributes.items():
        if len(usage) > 1:  # Shared resource
            resource_users = [n['id'] for n in nodes if resource in n['id']]
            for i in range(len(resource_users)):
                for j in range(i+1, len(resource_users)):
                    edges.append({
                        "source": resource_users[i],
                        "target": resource_users[j],
                        "type": "SHARES_RESOURCE"
                    })
    
    # Ensure minimum connectivity
    if len(edges) < len(nodes):
        for i in range(len(nodes) - 1):
            edges.append({
                "source": nodes[i]['id'],
                "target": nodes[i+1]['id'],
                "type": "CONNECTS_TO"
            })
    
    return {"nodes": nodes, "edges": edges}

def create_demo_graph():
    """Create a compelling demo graph for showcase"""
    return {
        "nodes": [
            {"id": "Customer Portal", "type": "Application"},
            {"id": "Payment System", "type": "Application"},
            {"id": "User Database", "type": "Database"},
            {"id": "Transaction DB", "type": "Database"},
            {"id": "Web Server", "type": "Server"},
            {"id": "DB Server", "type": "Server"},
            {"id": "John Smith", "type": "Person"},
            {"id": "Jane Doe", "type": "Person"},
            {"id": "DataCenter-A", "type": "Location"},
            {"id": "Oracle 19c", "type": "Technology"}
        ],
        "edges": [
            {"source": "Customer Portal", "target": "User Database", "type": "USES"},
            {"source": "Payment System", "target": "Transaction DB", "type": "USES"},
            {"source": "Customer Portal", "target": "Web Server", "type": "RUNS_ON"},
            {"source": "Payment System", "target": "Web Server", "type": "RUNS_ON"},
            {"source": "User Database", "target": "DB Server", "type": "RUNS_ON"},
            {"source": "Transaction DB", "target": "DB Server", "type": "RUNS_ON"},
            {"source": "John Smith", "target": "Customer Portal", "type": "MANAGES"},
            {"source": "Jane Doe", "target": "Payment System", "type": "MANAGES"},
            {"source": "Web Server", "target": "DataCenter-A", "type": "LOCATED_IN"},
            {"source": "DB Server", "target": "DataCenter-A", "type": "LOCATED_IN"},
            {"source": "User Database", "target": "Oracle 19c", "type": "RUNS_ON"},
            {"source": "Transaction DB", "target": "Oracle 19c", "type": "RUNS_ON"},
            {"source": "Customer Portal", "target": "Payment System", "type": "DEPENDS_ON"}
        ]
    }

def create_intelligent_fallback(text, structured_summary):
    """Create intelligent fallback graph based on data analysis"""
    st.write("**üîß Creating intelligent fallback graph...**")
    
    nodes = []
    edges = []
    
    # Analyze structured summary for entities
    if structured_summary and "HEADERS:" in structured_summary:
        lines = structured_summary.split('\n')
        headers = []
        rows = []
        
        for line in lines:
            if "HEADERS:" in line:
                headers = eval(line.split("HEADERS: ")[1])
            elif line.startswith("Row"):
                try:
                    row_data = eval(line.split(": ")[1])
                    rows.append(row_data)
                except:
                    continue
        
        # Create nodes from unique values
        entities = set()
        for row in rows:
            for key, value in row.items():
                if value and len(str(value)) > 2:
                    entity_type = determine_entity_type(key, str(value))
                    entities.add((str(value), entity_type))
        
        # Add nodes
        for entity, etype in list(entities)[:12]:
            nodes.append({"id": entity, "type": etype})
        
        # Create strategic relationships
        for row in rows:
            row_entities = [(str(v), k) for k, v in row.items() if v and len(str(v)) > 2]
            
            # Create all possible relationships within row
            for i in range(len(row_entities)):
                for j in range(i+1, len(row_entities)):
                    entity1, col1 = row_entities[i]
                    entity2, col2 = row_entities[j]
                    
                    rel_type = determine_relationship(col1, col2)
                    edges.append({
                        "source": entity1,
                        "target": entity2,
                        "type": rel_type
                    })
    
    # Ensure demo-worthy graph
    if len(nodes) < 6:
        demo_nodes = [
            {"id": "System Alpha", "type": "Application"},
            {"id": "Central Database", "type": "Database"},
            {"id": "Main Server", "type": "Server"},
            {"id": "System Admin", "type": "Person"},
            {"id": "Production", "type": "Environment"},
            {"id": "MySQL 8.0", "type": "Technology"}
        ]
        nodes.extend(demo_nodes[len(nodes):])
    
    if len(edges) < 8:
        demo_edges = [
            {"source": "System Alpha", "target": "Central Database", "type": "USES"},
            {"source": "System Alpha", "target": "Main Server", "type": "RUNS_ON"},
            {"source": "System Admin", "target": "System Alpha", "type": "MANAGES"},
            {"source": "Central Database", "target": "MySQL 8.0", "type": "RUNS_ON"},
            {"source": "System Alpha", "target": "Production", "type": "DEPLOYED_IN"},
            {"source": "Main Server", "target": "Production", "type": "LOCATED_IN"}
        ]
        edges.extend(demo_edges[len(edges):])
    
    return {"nodes": nodes[:12], "edges": edges[:15]}

def extract_json_multiple_ways(text):
    """Enhanced JSON extraction"""
    # Method 1: Direct JSON pattern
    json_patterns = [
        r'```json\s*(\{.*?\})\s*```',
        r'```\s*(\{.*?\})\s*```',
        r'(\{[^{}]*"nodes"[^{}]*"edges"[^{}]*\})',
        r'(\{.*?"nodes".*?"edges".*?\})'
    ]
    
    for pattern in json_patterns:
        matches = re.findall(pattern, text, re.DOTALL)
        for match in matches:
            result = try_parse_json(match)
            if result and validate_graph_structure(result):
                return result
    
    return None

def try_parse_json(json_str):
    """Try parsing JSON with common fixes"""
    try:
        cleaned = json_str.strip()
        cleaned = re.sub(r',(\s*[}\]])', r'\1', cleaned)
        cleaned = re.sub(r"'([^']*)':", r'"\1":', cleaned)
        
        result = json.loads(cleaned)
        return result if validate_graph_structure(result) else None
    except:
        return None

def validate_graph_structure(graph):
    """Validate graph has proper structure"""
    return (isinstance(graph, dict) and 
            "nodes" in graph and "edges" in graph and
            isinstance(graph["nodes"], list) and 
            isinstance(graph["edges"], list) and
            len(graph["nodes"]) >= 3 and
            len(graph["edges"]) >= 2)

def determine_entity_type(column_name, value):
    """Smart entity type determination"""
    col_lower = column_name.lower()
    val_lower = value.lower()
    
    type_mapping = {
        'Application': ['app', 'application', 'system', 'portal', 'platform'],
        'Database': ['database', 'db', 'data', 'oracle', 'mysql', 'sql'],
        'Server': ['server', 'host', 'machine', 'vm'],
        'Person': ['owner', 'manager', 'admin', 'user', 'contact'],
        'Location': ['location', 'site', 'datacenter', 'office', 'region'],
        'Technology': ['tech', 'technology', 'software', 'tool', 'framework'],
        'Environment': ['env', 'environment', 'stage', 'prod', 'dev']
    }
    
    for entity_type, keywords in type_mapping.items():
        if any(keyword in col_lower for keyword in keywords):
            return entity_type
        if any(keyword in val_lower for keyword in keywords):
            return entity_type
    
    return 'Component'

def determine_relationship(col1, col2):
    """Smart relationship determination"""
    col1_lower = col1.lower()
    col2_lower = col2.lower()
    
    relationship_rules = [
        (['owner', 'manager', 'admin'], ['app', 'system', 'database'], 'MANAGES'),
        (['app', 'system'], ['database', 'db'], 'USES'),
        (['app', 'system'], ['server', 'host'], 'RUNS_ON'),
        (['system', 'server'], ['location', 'site', 'datacenter'], 'LOCATED_IN'),
        (['app', 'system'], ['env', 'environment'], 'DEPLOYED_IN'),
        (['database', 'app'], ['technology', 'tech'], 'USES')
    ]
    
    for source_keywords, target_keywords, relationship in relationship_rules:
        if (any(kw in col1_lower for kw in source_keywords) and 
            any(kw in col2_lower for kw in target_keywords)):
            return relationship
    
    return 'RELATED_TO'

# =======================
# üé® POWER VISUALIZATION
# =======================
def create_power_visualization(graph_data, height=600):
    """Create compelling knowledge graph visualization"""
    
    analyzer = StrategicGraphAnalyzer(graph_data['nodes'], graph_data['edges'])
    criticality_scores = analyzer.get_node_criticality_scores()
    
    net = Network(
        height=f"{height}px", 
        width="100%", 
        directed=True,
        bgcolor="#1a1a1a",  # Dark theme for impact
        font_color="white"
    )
    
    # Enhanced physics for better layout
    net.set_options("""
    var options = {
      "physics": {
        "enabled": true,
        "stabilization": {"iterations": 200},
        "barnesHut": {
          "gravitationalConstant": -30000,
          "centralGravity": 0.1,
          "springLength": 150,
          "springConstant": 0.05,
          "damping": 0.3
        }
      },
      "nodes": {
        "font": {"size": 14, "color": "white"},
        "borderWidth": 3,
        "shadow": {"enabled": true, "color": "rgba(0,0,0,0.5)", "size": 10}
      },
      "edges": {
        "font": {"size": 12, "color": "white"},
        "arrows": {"to": {"enabled": true, "scaleFactor": 1.2}},
        "smooth": {"type": "continuous"},
        "width": 3
      }
    }
    """)
    
    # Enhanced color scheme
    type_colors = {
        'Application': '#FF6B6B',      # Red - Critical systems
        'Database': '#4ECDC4',         # Teal - Data systems
        'Server': '#45B7D1',           # Blue - Infrastructure
        'Person': '#FFA07A',           # Orange - People
        'Location': '#98D8C8',         # Green - Places
        'Technology': '#DDA0DD',       # Purple - Tech stack
        'Environment': '#F0E68C',      # Yellow - Environments
        'Component': '#D3D3D3'         # Gray - Generic
    }
    
    # Add nodes with criticality-based sizing
    for node in graph_data['nodes']:
        node_id = node['id']
        node_type = node.get('type', 'Component')
        
        # Calculate size based on criticality
        criticality = criticality_scores.get(node_id, 0.1)
        size = int(25 + (criticality * 40))  # 25-65 pixel range
        
        # Color intensity based on criticality
        base_color = type_colors.get(node_type, '#D3D3D3')
        
        # Enhanced tooltip with strategic info
        tooltip = f"""
        <div style='background: #2a2a2a; padding: 10px; border-radius: 5px; color: white;'>
        <h3>{node_id}</h3>
        <p><strong>Type:</strong> {node_type}</p>
        <p><strong>Criticality:</strong> {criticality:.2f}</p>
        <p><strong>Connections:</strong> {len([e for e in graph_data['edges'] if e['source'] == node_id or e['target'] == node_id])}</p>
        </div>
        """
        
        net.add_node(
            node_id,
            label=node_id,
            color=base_color,
            size=size,
            title=tooltip,
            shape='dot'
        )
    
    # Add edges with relationship-based styling
    edge_colors = {
        'MANAGES': '#E74C3C',
        'USES': '#3498DB',
        'RUNS_ON': '#2ECC71',
        'LOCATED_IN': '#F39C12',
        'DEPENDS_ON': '#E67E22',
        'SHARES_RESOURCE': '#9B59B6',
        'CONNECTS_TO': '#1ABC9C'
    }
    
    for edge in graph_data['edges']:
        edge_color = edge_colors.get(edge['type'], '#95A5A6')
        
        # Edge width based on relationship importance
        width = 4 if edge['type'] in ['MANAGES', 'DEPENDS_ON'] else 2
        
        net.add_edge(
            edge['source'],
            edge['target'],
            label=edge['type'],
            color=edge_color,
            width=width,
            title=f"{edge['source']} {edge['type']} {edge['target']}"
        )
    
    return net

# =======================
# üîç LANGGRAPH SETUP
# =======================
class GraphState(TypedDict):
    file: object
    text: str
    structured_summary: str
    graph: dict

def extract_step(state: GraphState):
    text = extract_text_from_file(state["file"])
    
    structured_summary = ""
    if text:
        lines = text.split('\n')
        if len(lines) > 1:
            # Parse CSV properly
            headers = [h.strip() for h in lines[0].split(',')]
            st.write("**üìã Detected Headers:**", headers)
            
            # Parse actual data rows
            data_rows = []
            for i in range(1, min(len(lines), 21)):  # Show first 20 rows
                if lines[i].strip():
                    row_data = [cell.strip() for cell in lines[i].split(',')]
                    if len(row_data) == len(headers):
                        data_rows.append(dict(zip(headers, row_data)))
            
            if data_rows:
                st.write("**üìä Sample Data (First 5 rows):**")
                for i, row in enumerate(data_rows[:5]):
                    st.write(f"Row {i+1}: {row}")
                
                # Create detailed structured summary
                structured_summary = f"CSV DATA ANALYSIS:\n\n"
                structured_summary += f"HEADERS: {headers}\n\n"
                structured_summary += f"TOTAL ROWS: {len(lines)-1}\n\n"
                structured_summary += f"SAMPLE DATA ROWS:\n"
                
                for i, row in enumerate(data_rows[:10]):
                    structured_summary += f"Row {i+1}: {row}\n"
                
                # Analyze column types
                structured_summary += f"\nCOLUMN ANALYSIS:\n"
                for header in headers:
                    values = [row.get(header, '') for row in data_rows if row.get(header, '').strip()]
                    unique_values = list(set(values))[:5]  # First 5 unique values
                    structured_summary += f"- {header}: {unique_values}\n"
    
    return {"text": text, "structured_summary": structured_summary}

def extract_kg_step(state: GraphState):
    return {"graph": llm_extract_graph(state["text"], state.get("structured_summary", ""))}

def build_graph_pipeline():
    workflow = StateGraph(GraphState)
    workflow.add_node("extract_text", extract_step)
    workflow.add_node("extract_kg", extract_kg_step)
    workflow.set_entry_point("extract_text")
    workflow.add_edge("extract_text", "extract_kg")
    workflow.add_edge("extract_kg", END)
    return workflow.compile()

# =======================
# üñºÔ∏è ENHANCED STREAMLIT UI
# =======================
def main():
    st.set_page_config(page_title="üîó Knowledge Graph Power Demo", layout="wide")
    
    # Hero header
    st.markdown("""
    <div style='text-align: center; padding: 20px; background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); border-radius: 10px; margin-bottom: 20px;'>
    <h1 style='color: white; margin: 0;'>üîó Knowledge Graph Power Demo</h1>
    <p style='color: white; margin: 0; font-size: 18px;'>Transform boring spreadsheets into intelligent, connected insights</p>
    </div>
    """, unsafe_allow_html=True)
    
    # LLM Status
    llm_status = "üü¢ Active" if LLM_USERNAME != "your_username_here" else "üî¥ Demo Mode"
    st.sidebar.markdown(f"**LLM Status:** {llm_status}")
    
    # File uploader
    uploaded = st.file_uploader(
        "üìÅ Upload Your Data", 
        type=["xlsx", "docx", "csv"],
        help="Upload Excel, Word, or CSV files to see the knowledge graph magic!"
    )

    if uploaded:
        st.markdown("### üîç Processing Your Data...")
        
        with st.spinner("üß† Analyzing data and creating knowledge graph..."):
            graph_pipeline = build_graph_pipeline()
            output = graph_pipeline.invoke({"file": uploaded})
            kg = output["graph"]
            text = output["text"]

        if kg.get("nodes"):
            st.success("‚úÖ **Knowledge Graph Generated!**")
            
            # Show the transformation
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("#### üìä Your Original Data")
                st.info("Rows and columns - hard to see relationships")
                if text:
                    st.code(text[:300] + "..." if len(text) > 300 else text)
            
            with col2:
                st.markdown("#### üåê Knowledge Graph Power")
                st.success("Connected insights - relationships revealed!")
                st.metric("Entities Discovered", len(kg['nodes']))
                st.metric("Relationships Mapped", len(kg['edges']))
            
            # Strategic Insights
            st.markdown("### üéØ Strategic Insights")
            analyzer = StrategicGraphAnalyzer(kg['nodes'], kg['edges'])
            insights = analyzer.analyze_strategic_insights()
            
            for insight in insights:
                if insight['type'] == 'critical':
                    st.error(f"**{insight['title']}**\n\n{insight['content']}")
                elif insight['type'] == 'risk':
                    st.warning(f"**{insight['title']}**\n\n{insight['content']}")
                elif insight['type'] == 'optimization':
                    st.info(f"**{insight['title']}**\n\n{insight['content']}")
                else:
                    st.success(f"**{insight['title']}**\n\n{insight['content']}")
            
            # Power Visualization
            st.markdown("### üåê Interactive Knowledge Graph")
            st.markdown("**Node size = Criticality | Color = Component Type | Click to explore**")
            
            try:
                net = create_power_visualization(kg)
                
                # Generate and display
                import uuid
                temp_file = f"power_graph_{uuid.uuid4().hex[:8]}.html"
                temp_path = os.path.join(tempfile.gettempdir(), temp_file)
                
                net.save_graph(temp_path)
                with open(temp_path, "r", encoding="utf-8") as f:
                    html = f.read()
                
                # Enhanced HTML with custom styling
                enhanced_html = f"""
                <div style="border: 2px solid #667eea; border-radius: 10px; overflow: hidden;">
                {html}
                </div>
                """
                
                st.components.v1.html(enhanced_html, height=650)
                
                # Cleanup
                try:
                    os.unlink(temp_path)
                except:
                    pass
                    
            except Exception as e:
                st.error(f"Visualization error: {e}")
                st.info("üí° Install pyvis: `pip install pyvis networkx`")
            
            # Network Analysis Dashboard
            st.markdown("### üìä Network Analysis Dashboard")
            
            col1, col2, col3, col4 = st.columns(4)
            
            # Calculate network metrics
            analyzer = StrategicGraphAnalyzer(kg['nodes'], kg['edges'])
            connectivity = dict(analyzer.graph.degree())
            
            with col1:
                avg_connections = sum(connectivity.values()) / len(connectivity) if connectivity else 0
                st.metric("Avg Connections", f"{avg_connections:.1f}")
            
            with col2:
                most_connected = max(connectivity.items(), key=lambda x: x[1]) if connectivity else ("None", 0)
                st.metric("Most Connected", most_connected[0][:15] + "..." if len(most_connected[0]) > 15 else most_connected[0], f"{most_connected[1]} connections")
            
            with col3:
                isolated_nodes = len([n for n, c in connectivity.items() if c == 0])
                st.metric("Isolated Nodes", isolated_nodes, delta="Lower is better" if isolated_nodes > 0 else "Perfect!")
            
            with col4:
                density = len(kg['edges']) / (len(kg['nodes']) * (len(kg['nodes']) - 1)) * 100 if len(kg['nodes']) > 1 else 0
                st.metric("Network Density", f"{density:.1f}%")
            
            # Node Details Explorer
            st.markdown("### üîç Node Details Explorer")
            
            if kg.get("nodes"):
                # Sort nodes by criticality
                criticality_scores = analyzer.get_node_criticality_scores()
                sorted_nodes = sorted(kg['nodes'], key=lambda x: criticality_scores.get(x['id'], 0), reverse=True)
                node_options = [f"{n['id']} ({n['type']}) - Criticality: {criticality_scores.get(n['id'], 0):.2f}" for n in sorted_nodes]
                
                selected_option = st.selectbox("üéØ Select node to explore:", node_options)
                
                if selected_option:
                    selected_node_id = selected_option.split(" (")[0]
                    selected_node = next((n for n in kg["nodes"] if n["id"] == selected_node_id), None)
                    
                    if selected_node:
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.markdown(f"#### üìå {selected_node_id}")
                            st.write(f"**Type:** {selected_node.get('type', 'Unknown')}")
                            st.write(f"**Criticality Score:** {criticality_scores.get(selected_node_id, 0):.2f}")
                            
                            # Connection count
                            connections = len([e for e in kg['edges'] if e['source'] == selected_node_id or e['target'] == selected_node_id])
                            st.write(f"**Total Connections:** {connections}")
                        
                        with col2:
                            st.markdown("#### üîó Relationships")
                            related_edges = [e for e in kg['edges'] if e['source'] == selected_node_id or e['target'] == selected_node_id]
                            
                            if related_edges:
                                for rel in related_edges:
                                    if rel['source'] == selected_node_id:
                                        st.write(f"üîπ **{selected_node_id}** ‚Üí *{rel['type']}* ‚Üí **{rel['target']}**")
                                    else:
                                        st.write(f"üî∏ **{rel['source']}** ‚Üí *{rel['type']}* ‚Üí **{selected_node_id}**")
                            else:
                                st.write("No relationships found")
                        
                        # Impact Analysis
                        st.markdown("#### ‚ö° Impact Analysis")
                        
                        # What would be affected if this node fails
                        affected_nodes = set()
                        for edge in kg['edges']:
                            if edge['source'] == selected_node_id:
                                affected_nodes.add(edge['target'])
                        
                        if affected_nodes:
                            st.error(f"üö® **{len(affected_nodes)} components would be directly impacted** if {selected_node_id} fails:")
                            for node in list(affected_nodes)[:5]:
                                st.write(f"‚Ä¢ {node}")
                            if len(affected_nodes) > 5:
                                st.write(f"‚Ä¢ ... and {len(affected_nodes) - 5} more")
                        else:
                            st.success("‚úÖ No direct dependencies - low impact component")
            
            # Download Options
            st.markdown("### üíæ Export Options")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.download_button(
                    "üì• Download Graph JSON",
                    json.dumps(kg, indent=2),
                    file_name="knowledge_graph.json",
                    mime="application/json"
                )
            
            with col2:
                # Create insights report
                insights_report = "# Strategic Insights Report\n\n"
                for insight in insights:
                    insights_report += f"## {insight['title']}\n{insight['content']}\n\n"
                
                st.download_button(
                    "üìÑ Download Insights Report",
                    insights_report,
                    file_name="strategic_insights.md",
                    mime="text/markdown"
                )
            
            with col3:
                # Create network metrics
                metrics_data = {
                    "total_nodes": len(kg['nodes']),
                    "total_edges": len(kg['edges']),
                    "network_density": density,
                    "avg_connections": avg_connections,
                    "most_connected_node": most_connected[0],
                    "isolated_nodes": isolated_nodes
                }
                
                st.download_button(
                    "üìä Download Metrics",
                    json.dumps(metrics_data, indent=2),
                    file_name="network_metrics.json",
                    mime="application/json"
                )
            
            # Enhanced Chat Interface
            st.markdown("### üí¨ Strategic Chat Interface")
            st.markdown("Ask strategic questions about your architecture and get AI-powered insights!")
            
            # Initialize chat history
            if "chat_history" not in st.session_state:
                st.session_state.chat_history = []
            
            # Display chat history
            if st.session_state.chat_history:
                st.markdown("#### üí≠ Conversation History")
                for i, chat in enumerate(st.session_state.chat_history):
                    with st.expander(f"üí¨ Question {i+1}: {chat['question'][:50]}..."):
                        st.markdown(f"**üôã Question:** {chat['question']}")
                        st.markdown(f"**ü§ñ Answer:** {chat['answer']}")
            
            # Strategic question suggestions
            if not st.session_state.chat_history:
                st.markdown("#### üí° Strategic Questions to Try:")
                
                strategic_questions = [
                    "What are the biggest risks in this architecture?",
                    "Which components are most critical to business operations?",
                    "What would happen if the most connected component failed?",
                    "Are there any single points of failure I should be concerned about?",
                    "What systems share the most resources?"
                ]
                
                cols = st.columns(2)
                for i, question in enumerate(strategic_questions):
                    with cols[i % 2]:
                        if st.button(f"üí≠ {question}", key=f"strategic_q_{i}"):
                            st.session_state.strategic_question = question
                            st.rerun()
            
            # Chat input
            user_question = st.text_input(
                "üéØ Ask a strategic question:",
                value=st.session_state.get('strategic_question', ''),
                placeholder="e.g., What are the risks if the main database fails?",
                key="strategic_chat_input"
            )
            
            col1, col2 = st.columns([1, 4])
            with col1:
                ask_button = st.button("üöÄ Ask", type="primary")
            with col2:
                if st.button("üóëÔ∏è Clear History"):
                    st.session_state.chat_history = []
                    st.rerun()
            
            if ask_button and user_question:
                if LLM_USERNAME == "your_username_here":
                    st.info("üîß Configure LLM credentials for strategic chat capabilities")
                else:
                    # Enhanced context with strategic insights
                    strategic_context = f"""
STRATEGIC KNOWLEDGE GRAPH ANALYSIS:

NETWORK OVERVIEW:
- Total Components: {len(kg['nodes'])}
- Total Relationships: {len(kg['edges'])}
- Network Density: {density:.1f}%

ENTITIES:
{chr(10).join([f"- {n['id']} ({n['type']})" for n in kg['nodes']])}

RELATIONSHIPS:
{chr(10).join([f"- {e['source']} {e['type']} {e['target']}" for e in kg['edges']])}

STRATEGIC INSIGHTS:
{chr(10).join([f"- {insight['title']}: {insight['content']}" for insight in insights])}

CRITICALITY SCORES:
{chr(10).join([f"- {node}: {score:.2f}" for node, score in sorted(criticality_scores.items(), key=lambda x: x[1], reverse=True)[:5]])}

ORIGINAL DATA CONTEXT:
{text[:1000]}
"""
                    
                    enhanced_prompt = f"""You are a strategic IT architect analyzing a knowledge graph. Provide strategic, actionable insights.

{strategic_context}

USER QUESTION: {user_question}

Provide a comprehensive strategic answer that:
1. References specific components and relationships
2. Identifies business risks and opportunities
3. Gives actionable recommendations
4. Uses the criticality scores and network analysis

STRATEGIC ANSWER:"""
                    
                    try:
                        headers = {"Authorization": f"Basic {get_basic_auth()}", "Content-Type": "application/json"}
                        payload = {"inputs": enhanced_prompt, "parameters": {"temperature": 0.3, "max_new_tokens": 600}}
                        
                        with st.spinner("üß† Analyzing strategic implications..."):
                            response = requests.post(LLM_API_URL, headers=headers, json=payload, timeout=45)
                            
                            if response.status_code == 200:
                                resp_json = response.json()
                                
                                if "generated_text" in resp_json:
                                    raw_answer = resp_json["generated_text"]
                                elif isinstance(resp_json, list):
                                    raw_answer = resp_json[0].get("generated_text", str(resp_json))
                                else:
                                    raw_answer = str(resp_json)
                                
                                # Clean the answer
                                if "STRATEGIC ANSWER:" in raw_answer:
                                    answer = raw_answer.split("STRATEGIC ANSWER:")[-1].strip()
                                else:
                                    answer = raw_answer
                                
                                # Add to chat history
                                st.session_state.chat_history.append({
                                    "question": user_question,
                                    "answer": answer
                                })
                                
                                # Display the answer immediately
                                st.markdown("#### ü§ñ Strategic Analysis:")
                                st.markdown(answer)
                                
                                st.rerun()
                            else:
                                st.error(f"Strategic analysis failed: {response.status_code}")
                    except Exception as e:
                        st.error(f"Strategic analysis error: {e}")
        else:
            st.warning("‚ö†Ô∏è Could not generate knowledge graph from uploaded data")
            st.info("üí° Try uploading a CSV or Excel file with clear column headers")
    
    else:
        # Landing page content
        st.markdown("""
        ### üöÄ See the Power of Knowledge Graphs
        
        **Transform your boring spreadsheets into strategic insights!**
        
        Upload any Excel, CSV, or Word document and watch as we:
        """)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("""
            #### üîç **Discover Hidden Connections**
            - Find relationships between systems
            - Identify dependencies and risks
            - Reveal critical components
            """)
        
        with col2:
            st.markdown("""
            #### üìä **Strategic Analysis**
            - Risk assessment and impact analysis
            - Single points of failure detection
            - Management gap identification
            """)
        
        with col3:
            st.markdown("""
            #### üí¨ **AI-Powered Insights**
            - Ask strategic questions
            - Get actionable recommendations
            - Understand business impact
            """)
        
        st.markdown("""
        ---
        
        ### üí° **Example Use Cases:**
        
        - **IT Asset Management** ‚Üí See which systems depend on each other
        - **Risk Assessment** ‚Üí Identify critical failure points
        - **Architecture Review** ‚Üí Understand system relationships
        - **Strategic Planning** ‚Üí Make informed decisions about infrastructure
        
        **Ready to see your data in a whole new way?** Upload a file above! üëÜ
        """)

if __name__ == "__main__":
    main()
