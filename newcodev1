# =======================
# üì¶ IMPORTS
# =======================
import streamlit as st
import pandas as pd
import json
import base64
import re
import requests
from pyvis.network import Network
import tempfile
import os
import streamlit.components.v1 as components

# =======================
# üîß CONFIGURATION
# =======================
st.set_page_config(page_title="Knowledge Graph Builder", layout="wide")

# LLM Configuration
LLM_API_URL = "https://your-llm-endpoint.com/v1/chat/completions"
LLM_USERNAME = "your_username_here"  # Replace with actual username
LLM_PASSWORD = "your_password_here"  # Replace with actual password

# =======================
# üõ†Ô∏è UTILITY FUNCTIONS
# =======================
def get_basic_auth():
    """Create basic auth header"""
    creds = f"{LLM_USERNAME}:{LLM_PASSWORD}"
    return base64.b64encode(creds.encode()).decode()

def validate_graph(graph_data):
    """Validate graph structure"""
    return (isinstance(graph_data, dict) and 
            "nodes" in graph_data and "edges" in graph_data and
            isinstance(graph_data["nodes"], list) and 
            isinstance(graph_data["edges"], list) and
            len(graph_data["nodes"]) >= 3 and
            len(graph_data["edges"]) >= 2)

# =======================
# üìÑ DATA EXTRACTION FUNCTIONS
# =======================
def extract_data_from_excel(file):
    """Extract and structure data from Excel file"""
    try:
        df = pd.read_excel(file)
        
        # Show basic info
        st.write("**üìã File Info:**")
        st.write(f"- Rows: {len(df)}")
        st.write(f"- Columns: {len(df.columns)}")
        st.write(f"- Headers: {list(df.columns)}")
        
        # Show sample data
        st.write("**üìä Sample Data:**")
        st.dataframe(df.head())
        
        # Create structured summary for LLM
        summary = f"EXCEL DATA ANALYSIS:\n\n"
        summary += f"HEADERS: {list(df.columns)}\n\n"
        summary += f"TOTAL ROWS: {len(df)}\n\n"
        summary += f"SAMPLE DATA ROWS:\n"
        
        for i, row in df.head(10).iterrows():
            row_dict = row.to_dict()
            summary += f"Row {i+1}: {row_dict}\n"
        
        return summary
        
    except Exception as e:
        st.error(f"Error reading Excel file: {e}")
        return None

# =======================
# üß™ LLM TESTING FUNCTIONS
# =======================
def test_llm_connection():
    """Test LLM with a simple request to see what format it expects"""
    st.write("**üß™ Testing LLM with simple request...**")
    
    # Simple test prompt
    test_prompt = "Hello, please respond with: SUCCESS"
    
    # Try different payload formats that Llama APIs commonly use
    payload_formats = [
        # Format 1: Standard
        {
            "inputs": test_prompt,
            "parameters": {"temperature": 0.1, "max_new_tokens": 50}
        },
        # Format 2: Messages format
        {
            "messages": [{"role": "user", "content": test_prompt}],
            "temperature": 0.1,
            "max_tokens": 50
        },
        # Format 3: Prompt field
        {
            "prompt": test_prompt,
            "temperature": 0.1,
            "max_tokens": 50
        },
        # Format 4: Text field
        {
            "text": test_prompt,
            "parameters": {"temperature": 0.1, "max_new_tokens": 50}
        }
    ]
    
    headers = {
        "Authorization": f"Basic {get_basic_auth()}", 
        "Content-Type": "application/json"
    }
    
    for i, payload in enumerate(payload_formats, 1):
        try:
            st.write(f"**Testing Format {i}:** {list(payload.keys())}")
            response = requests.post(LLM_API_URL, headers=headers, json=payload, timeout=30)
            
            if response.status_code == 200:
                try:
                    resp_json = response.json()
                    st.write(f"‚úÖ Format {i} - Status 200:")
                    st.json(resp_json)
                    
                    # Check if we got actual content
                    content = ""
                    if isinstance(resp_json, dict):
                        for key in ["generated_text", "output", "response", "text", "content"]:
                            if key in resp_json:
                                content = resp_json[key]
                                break
                    elif isinstance(resp_json, list) and len(resp_json) > 0:
                        for key in ["generated_text", "output", "response", "text", "content"]:
                            if key in resp_json[0]:
                                content = resp_json[0][key]
                                break
                    
                    if content and "SUCCESS" in str(content):
                        st.success(f"üéâ Format {i} WORKS! Use this format.")
                        return i, payload_formats[i-1]
                    else:
                        st.warning(f"Format {i} returned empty or unexpected content")
                        
                except json.JSONDecodeError:
                    st.error(f"Format {i} - Invalid JSON response")
                    st.code(response.text[:200])
            else:
                st.error(f"Format {i} - Status {response.status_code}: {response.text[:100]}")
                
        except Exception as e:
            st.error(f"Format {i} - Error: {e}")
    
    return None, None

# =======================
# üéØ ENTITY EXTRACTION FUNCTIONS
# =======================
def extract_json_from_text(text):
    """Extract JSON from LLM response - ultra-simple approach"""
    
    st.write("**üîç Raw LLM Response (first 500 chars):**")
    st.code(text[:500])
    
    # Skip JSON entirely - just extract entities from text
    st.write("**üéØ Extracting entities directly from text (no JSON)...**")
    return extract_entities_from_text(text)

def extract_entities_from_text(text):
    """Extract entities with proper centroids and meaningful relationships"""
    
    # Find all quoted strings and capitalized words
    quoted_entities = re.findall(r'"([^"]{2,30})"', text)
    quoted_entities += re.findall(r"'([^']{2,30})'", text)
    capitalized_words = re.findall(r'\b[A-Z][a-zA-Z\s]{2,25}\b', text)
    
    # Combine and clean entities
    all_entities = list(set(quoted_entities + capitalized_words))
    
    st.write(f"**Found {len(all_entities)} potential entities:**")
    for entity in all_entities[:10]:
        st.write(f"- {entity}")
    
    if len(all_entities) < 3:
        return create_minimal_demo_graph()
    
    # SMART ENTITY CLASSIFICATION with centroids
    nodes = []
    systems = []
    people = []
    technologies = []
    databases = []
    servers = []
    locations = []
    
    for entity in all_entities[:12]:  # More entities for better centroids
        entity = entity.strip()
        entity_lower = entity.lower()
        
        # Classify entities more precisely
        if any(word in entity_lower for word in ['system', 'app', 'application', 'portal', 'platform', 'management', 'service']):
            node_type = "Application"
            systems.append(entity)
        elif any(word in entity_lower for word in ['database', 'db', 'data', 'warehouse']):
            node_type = "Database" 
            databases.append(entity)
        elif any(word in entity_lower for word in ['server', 'host', 'machine', 'vm', 'infrastructure']):
            node_type = "Server"
            servers.append(entity)
        elif any(word in entity_lower for word in ['windows', 'linux', 'oracle', 'mysql', 'java', 'python', 'apache']):
            node_type = "Technology"
            technologies.append(entity)
        elif any(word in entity_lower for word in ['datacenter', 'center', 'site', 'location', 'office', 'cloud']):
            node_type = "Location"
            locations.append(entity)
        elif len(entity.split()) == 2 and entity.istitle() and not any(tech in entity_lower for tech in ['system', 'server', 'database']):
            node_type = "Person"
            people.append(entity)
        else:
            node_type = "Component"
            systems.append(entity)  # Default unknown to systems
        
        nodes.append({"id": entity, "type": node_type})
    
    st.write("**Entity Classification:**")
    st.write(f"- Applications: {len(systems)} - {systems[:3]}")
    st.write(f"- People: {len(people)} - {people[:3]}")
    st.write(f"- Technologies: {len(technologies)} - {technologies[:3]}")
    st.write(f"- Databases: {len(databases)} - {databases[:3]}")
    st.write(f"- Servers: {len(servers)} - {servers[:3]}")
    st.write(f"- Locations: {len(locations)} - {locations[:3]}")
    
    # CREATE MEANINGFUL RELATIONSHIPS with centroids
    edges = []
    
    # 1. MANAGEMENT RELATIONSHIPS (People ‚Üí Systems)
    for person in people:
        for system in systems[:2]:  # Each person manages 1-2 systems
            edges.append({
                "source": person,
                "target": system,
                "type": "MANAGES"
            })
    
    # 2. USAGE RELATIONSHIPS (Systems ‚Üí Databases/Technologies)
    for system in systems:
        # Systems use databases
        for db in databases[:1]:  # Each system uses 1 database
            edges.append({
                "source": system,
                "target": db,
                "type": "USES"
            })
        # Systems use technologies
        for tech in technologies[:1]:  # Each system uses 1 technology
            edges.append({
                "source": system,
                "target": tech,
                "type": "RUNS_ON"
            })
    
    # 3. HOSTING RELATIONSHIPS (Systems/Databases ‚Üí Servers)
    for server in servers:
        # Systems run on servers
        for system in systems[:2]:  # Each server hosts 2 systems
            edges.append({
                "source": system,
                "target": server,
                "type": "HOSTED_ON"
            })
        # Databases run on servers
        for db in databases[:1]:  # Each server hosts 1 database
            edges.append({
                "source": db,
                "target": server,
                "type": "HOSTED_ON"
            })
    
    # 4. LOCATION RELATIONSHIPS (Servers ‚Üí Locations)
    for server in servers:
        for location in locations[:1]:  # Each server is in 1 location
            edges.append({
                "source": server,
                "target": location,
                "type": "LOCATED_IN"
            })
    
    # 5. DEPENDENCY RELATIONSHIPS (System ‚Üí System)
    if len(systems) > 1:
        for i in range(len(systems) - 1):
            edges.append({
                "source": systems[i],
                "target": systems[i + 1],
                "type": "DEPENDS_ON"
            })
    
    # 6. SHARED RESOURCE RELATIONSHIPS
    if len(systems) > 1 and databases:
        # Multiple systems sharing same database
        main_db = databases[0]
        for system in systems[1:]:  # All systems except first
            edges.append({
                "source": system,
                "target": main_db,
                "type": "SHARES_DATA"
            })
    
    # IDENTIFY CENTROIDS (most connected entities)
    node_connections = {}
    for edge in edges:
        source = edge['source']
        target = edge['target']
        node_connections[source] = node_connections.get(source, 0) + 1
        node_connections[target] = node_connections.get(target, 0) + 1
    
    # Find top centroids
    centroids = sorted(node_connections.items(), key=lambda x: x[1], reverse=True)[:3]
    
    st.write("**üéØ Identified Centroids (Most Connected):**")
    for centroid, connections in centroids:
        st.write(f"- **{centroid}**: {connections} connections")
    
    result = {"nodes": nodes, "edges": edges}
    
    st.success(f"‚úÖ Created sophisticated graph: {len(nodes)} entities, {len(edges)} relationships")
    
    # Show relationship breakdown
    rel_types = {}
    for edge in edges:
        rel_type = edge['type']
        rel_types[rel_type] = rel_types.get(rel_type, 0) + 1
    
    st.write("**üîó Relationship Types Created:**")
    for rtype, count in rel_types.items():
        st.write(f"- **{rtype}**: {count} connections")
    
    return result

def create_minimal_demo_graph():
    """Create absolute minimal graph when everything else fails"""
    st.write("**üîß Creating minimal demo graph...**")
    
    nodes = [
        {"id": "System A", "type": "Application"},
        {"id": "Database B", "type": "Database"},
        {"id": "Server C", "type": "Server"},
        {"id": "Admin User", "type": "Person"}
    ]
    
    edges = [
        {"source": "System A", "target": "Database B", "type": "USES"},
        {"source": "System A", "target": "Server C", "type": "RUNS_ON"},
        {"source": "Admin User", "target": "System A", "type": "MANAGES"}
    ]
    
    return {"nodes": nodes, "edges": edges}

# =======================
# ü§ñ LLM KNOWLEDGE GRAPH FUNCTIONS
# =======================
def create_knowledge_graph_with_llm(data_summary):
    """Use LLM to extract knowledge graph - with format testing and simplified prompt"""
    
    # Test LLM first
    working_format_num, working_format = test_llm_connection()
    
    if not working_format:
        st.error("‚ùå None of the common API formats worked. Check your LLM API documentation.")
        return None
    
    st.success(f"‚úÖ Using working format {working_format_num}")
    
    # SIMPLIFIED prompt that works better with Llama
    prompt = f"""Extract entities and relationships from this business data. Return JSON only.

Data:
{data_summary[:1000]}  

Create a knowledge graph with:
- Entities: People, Systems, Technologies, Locations
- Relationships: MANAGES, USES, DEPENDS_ON, LOCATED_IN

Format:
{{"nodes": [{{"id": "EntityName", "type": "EntityType"}}], "edges": [{{"source": "Source", "target": "Target", "type": "RELATIONSHIP"}}]}}

JSON:"""

    # Build payload using working format
    payload = {
        "inputs": prompt,
        "parameters": {"temperature": 0.1, "max_new_tokens": 600}  # Reduced tokens
    }
    
    try:
        headers = {
            "Authorization": f"Basic {get_basic_auth()}", 
            "Content-Type": "application/json"
        }
        
        st.write(f"**üìù Simplified prompt length:** {len(prompt)} characters")
        
        with st.spinner("üß† Creating knowledge graph with simplified prompt..."):
            response = requests.post(LLM_API_URL, headers=headers, json=payload, timeout=45)
        
        if response.status_code == 200:
            resp_json = response.json()
            
            # Extract content using the same method that worked in test
            content = ""
            if isinstance(resp_json, dict):
                for key in ["generated_text", "output", "response", "text", "content"]:
                    if key in resp_json and resp_json[key]:
                        content = resp_json[key]
                        break
            elif isinstance(resp_json, list) and len(resp_json) > 0:
                for key in ["generated_text", "output", "response", "text", "content"]:
                    if key in resp_json[0] and resp_json[0][key]:
                        content = resp_json[0][key]
                        break
            
            if not content:
                st.error("‚ùå LLM returned empty content even with simplified prompt")
                st.write("**Trying even shorter prompt...**")
                return try_minimal_prompt(data_summary)
            
            # Clean response
            if "JSON:" in content:
                content = content.split("JSON:")[-1].strip()
            
            st.write("**ü§ñ LLM Response:**")
            st.code(content[:300] + "..." if len(content) > 300 else content)
            
            # Extract JSON from response
            graph_data = extract_json_from_text(content)
            
            if graph_data and validate_graph(graph_data):
                st.success(f"‚úÖ Knowledge Graph Created: {len(graph_data['nodes'])} entities, {len(graph_data['edges'])} relationships")
                return graph_data
            else:
                st.warning("‚ö†Ô∏è Could not extract valid graph, trying minimal prompt...")
                return try_minimal_prompt(data_summary)
        else:
            st.error(f"‚ùå LLM API Error: {response.status_code} - {response.text}")
            return None
            
    except Exception as e:
        st.error(f"‚ùå Error calling LLM: {e}")
        return None

def try_minimal_prompt(data_summary):
    """Last resort: ultra-minimal prompt"""
    st.write("**üî¨ Trying ultra-minimal prompt...**")
    
    # Extract just the first few rows of data
    lines = data_summary.split('\n')
    sample_data = '\n'.join(lines[:10])  # Just first 10 lines
    
    minimal_prompt = f"""Make a simple graph from this data:

{sample_data}

Return this format:
{{"nodes":[{{"id":"Name","type":"Type"}}],"edges":[{{"source":"A","target":"B","type":"USES"}}]}}"""

    payload = {
        "inputs": minimal_prompt,
        "parameters": {"temperature": 0.1, "max_new_tokens": 300}
    }
    
    try:
        headers = {
            "Authorization": f"Basic {get_basic_auth()}", 
            "Content-Type": "application/json"
        }
        
        st.write(f"**üìù Minimal prompt length:** {len(minimal_prompt)} characters")
        
        response = requests.post(LLM_API_URL, headers=headers, json=payload, timeout=30)
        
        if response.status_code == 200:
            resp_json = response.json()
            
            content = ""
            if isinstance(resp_json, dict) and "generated_text" in resp_json:
                content = resp_json["generated_text"]
            elif isinstance(resp_json, list) and len(resp_json) > 0 and "generated_text" in resp_json[0]:
                content = resp_json[0]["generated_text"]
            
            if content:
                st.write("**ü§ñ Minimal Response:**")
                st.code(content)
                
                # Try to extract JSON
                graph_data = extract_json_from_text(content)
                
                if graph_data and validate_graph(graph_data):
                    st.success(f"‚úÖ Minimal Graph Created: {len(graph_data['nodes'])} entities, {len(graph_data['edges'])} relationships")
                    return graph_data
                else:
                    st.error("‚ùå Even minimal prompt failed to generate valid graph")
                    return create_basic_fallback_from_data(data_summary)
            else:
                st.error("‚ùå Minimal prompt also returned empty")
                return create_basic_fallback_from_data(data_summary)
        else:
            st.error(f"‚ùå Minimal prompt failed: {response.status_code}")
            return create_basic_fallback_from_data(data_summary)
            
    except Exception as e:
        st.error(f"‚ùå Minimal prompt error: {e}")
        return create_basic_fallback_from_data(data_summary)

def create_basic_fallback_from_data(data_summary):
    """Create a basic graph directly from the data without LLM"""
    st.write("**üõ†Ô∏è Creating basic graph from data patterns...**")
    
    nodes = []
    edges = []
    
    # Simple pattern matching from the data
    lines = data_summary.split('\n')
    
    # Look for sample data rows
    for line in lines:
        if line.startswith("Row") and ":" in line:
            try:
                row_str = line.split(": ", 1)[1]
                row_data = eval(row_str)
                
                # Extract entities from row
                for key, value in row_data.items():
                    if value and len(str(value).strip()) > 2:
                        value_clean = str(value).strip()
                        
                        # Determine entity type from column name
                        if any(word in key.lower() for word in ['system', 'application', 'app']):
                            nodes.append({"id": value_clean, "type": "Application"})
                        elif any(word in key.lower() for word in ['person', 'owner', 'manager', 'user']):
                            nodes.append({"id": value_clean, "type": "Person"})
                        elif any(word in key.lower() for word in ['database', 'db', 'data']):
                            nodes.append({"id": value_clean, "type": "Database"})
                        elif any(word in key.lower() for word in ['server', 'host', 'machine']):
                            nodes.append({"id": value_clean, "type": "Server"})
                        elif any(word in key.lower() for word in ['location', 'site', 'datacenter']):
                            nodes.append({"id": value_clean, "type": "Location"})
                        else:
                            nodes.append({"id": value_clean, "type": "Component"})
                
            except:
                continue
    
    # Remove duplicates
    unique_nodes = []
    seen_ids = set()
    for node in nodes:
        if node['id'] not in seen_ids:
            unique_nodes.append(node)
            seen_ids.add(node['id'])
    
    nodes = unique_nodes[:10]  # Limit to 10 nodes
    
    # Create simple relationships
    for i in range(len(nodes) - 1):
        edges.append({
            "source": nodes[i]['id'],
            "target": nodes[i + 1]['id'],
            "type": "CONNECTS_TO"
        })
    
    if len(nodes) >= 3 and len(edges) >= 2:
        st.success(f"‚úÖ Basic graph created: {len(nodes)} entities, {len(edges)} relationships")
        return {"nodes": nodes, "edges": edges}
    else:
        st.error("‚ùå Could not create graph from data")
        return None

# =======================
# üé® VISUALIZATION FUNCTIONS
# =======================
def create_pyvis_graph(graph_data):
    """Create interactive pyvis visualization with centroid emphasis"""
    
    # Validate data first
    if not graph_data or 'nodes' not in graph_data or 'edges' not in graph_data:
        st.error("‚ùå Invalid graph data structure")
        return None
    
    nodes = graph_data['nodes']
    edges = graph_data['edges']
    
    if len(nodes) < 2:
        st.error("‚ùå Need at least 2 nodes for visualization")
        return None
    
    # Calculate node connectivity (centroids)
    node_connections = {}
    for edge in edges:
        source = edge['source']
        target = edge['target']
        node_connections[source] = node_connections.get(source, 0) + 1
        node_connections[target] = node_connections.get(target, 0) + 1
    
    # Find centroids (top 3 most connected)
    centroids = sorted(node_connections.items(), key=lambda x: x[1], reverse=True)[:3]
    centroid_nodes = set([c[0] for c in centroids])
    
    try:
        net = Network(
            height="600px", 
            width="100%", 
            directed=True,
            bgcolor="#f8f9fa"
        )
        
        # Enhanced color scheme with centroid emphasis
        type_colors = {
            'Application': '#FF6B6B',
            'Database': '#4ECDC4', 
            'Server': '#45B7D1',
            'Person': '#FFA07A',
            'Location': '#98D8C8',
            'Technology': '#DDA0DD',
            'Component': '#D3D3D3'
        }
        
        # Add nodes with centroid-based sizing
        valid_node_ids = set()
        for node in nodes:
            if isinstance(node, dict) and 'id' in node:
                node_id = str(node['id']).strip()
                node_type = str(node.get('type', 'Component'))
                
                if node_id and len(node_id) > 0:
                    # Size based on connectivity (centroids are larger)
                    connections = node_connections.get(node_id, 0)
                    if node_id in centroid_nodes:
                        size = 40 + (connections * 5)  # Centroids are much larger
                        border_width = 4
                    else:
                        size = 20 + (connections * 2)  # Regular nodes
                        border_width = 2
                    
                    color = type_colors.get(node_type, '#D3D3D3')
                    
                    # Special styling for centroids
                    if node_id in centroid_nodes:
                        # Add border to centroids
                        net.add_node(
                            node_id,
                            label=f"‚≠ê {node_id[:15]}",  # Star for centroids
                            color={'background': color, 'border': '#2E8B57', 'highlight': {'background': color, 'border': '#FF4500'}},
                            size=size,
                            title=f"üéØ CENTROID: {node_type} ({connections} connections)",
                            borderWidth=border_width,
                            font={'size': 14, 'color': 'black', 'face': 'arial'}
                        )
                    else:
                        net.add_node(
                            node_id,
                            label=node_id[:15],
                            color=color,
                            size=size,
                            title=f"Type: {node_type} ({connections} connections)",
                            borderWidth=border_width
                        )
                    valid_node_ids.add(node_id)
        
        st.write(f"**‚úÖ Added {len(valid_node_ids)} nodes ({len(centroid_nodes)} centroids)**")
        
        # Enhanced edge styling based on relationship type
        edge_colors = {
            'MANAGES': '#E74C3C',       # Red - Management
            'USES': '#3498DB',          # Blue - Usage  
            'RUNS_ON': '#2ECC71',       # Green - Technology
            'HOSTED_ON': '#F39C12',     # Orange - Hosting
            'LOCATED_IN': '#9B59B6',    # Purple - Location
            'DEPENDS_ON': '#E67E22',    # Dark Orange - Dependencies
            'SHARES_DATA': '#1ABC9C',   # Teal - Data sharing
            'CONNECTS_TO': '#95A5A6'    # Gray - Generic
        }
        
        edge_widths = {
            'MANAGES': 4,      # Management is important
            'DEPENDS_ON': 4,   # Dependencies are critical
            'USES': 3,         # Usage relationships
            'RUNS_ON': 3,      # Technology relationships
            'HOSTED_ON': 2,    # Hosting
            'SHARES_DATA': 2,  # Data sharing
            'LOCATED_IN': 1,   # Location
            'CONNECTS_TO': 1   # Generic
        }
        
        # Add edges with enhanced styling
        valid_edges = 0
        for edge in edges:
            if isinstance(edge, dict) and 'source' in edge and 'target' in edge:
                source = str(edge['source']).strip()
                target = str(edge['target']).strip()
                edge_type = str(edge.get('type', 'CONNECTS_TO'))
                
                if source in valid_node_ids and target in valid_node_ids and source != target:
                    color = edge_colors.get(edge_type, '#95A5A6')
                    width = edge_widths.get(edge_type, 2)
                    
                    net.add_edge(
                        source,
                        target,
                        label=edge_type,
                        color=color,
                        width=width,
                        title=f"{source} {edge_type} {target}",
                        arrows={'to': {'enabled': True, 'scaleFactor': 1.2}}
                    )
                    valid_edges += 1
                else:
                    st.warning(f"‚ö†Ô∏è Skipping invalid edge: {source} ‚Üí {target}")
        
        st.write(f"**‚úÖ Added {valid_edges} edges with enhanced styling**")
        
        # Physics settings for better centroid visibility
        net.set_options("""
        var options = {
          "physics": {
            "enabled": true,
            "stabilization": {"iterations": 100},
            "barnesHut": {
              "gravitationalConstant": -2000,
              "centralGravity": 0.3,
              "springLength": 200,
              "springConstant": 0.04,
              "damping": 0.09
            }
          },
          "layout": {
            "improvedLayout": true
          }
        }
        """)
        
        return net
        
    except Exception as e:
        st.error(f"‚ùå Pyvis error: {e}")
        st.info("üí° Try restarting Streamlit or check pyvis installation")
        return None

# =======================
# üñºÔ∏è MAIN APPLICATION
# =======================
def main():
    # Header
    st.title("üîó Knowledge Graph Builder")
    st.markdown("Upload an Excel file and let AI create a knowledge graph showing hidden connections!")
    
    # LLM Status
    llm_configured = LLM_USERNAME != "your_username_here"
    status = "üü¢ Connected" if llm_configured else "üî¥ Configure LLM credentials"
    st.sidebar.markdown(f"**LLM Status:** {status}")
    
    if not llm_configured:
        st.sidebar.warning("Update LLM_USERNAME and LLM_PASSWORD in the code")
    
    # File upload
    uploaded_file = st.file_uploader(
        "üìÅ Upload Excel File", 
        type=['xlsx', 'xls'],
        help="Upload an Excel file with your data"
    )
    
    if uploaded_file:
        # Extract data
        data_summary = extract_data_from_excel(uploaded_file)
        
        if data_summary:
            # Create knowledge graph
            st.markdown("---")
            st.markdown("### üß† Creating Knowledge Graph")
            
            if llm_configured:
                graph_data = create_knowledge_graph_with_llm(data_summary)
            else:
                st.error("‚ö†Ô∏è Configure LLM credentials to create knowledge graph")
                return
            
            if not graph_data:
                st.error("‚ùå Failed to create knowledge graph")
                return
            
            # Show graph details
            st.markdown("### üìä Graph Details")
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("Entities (Nouns)", len(graph_data['nodes']))
                
                # Show entity types
                entity_types = {}
                for node in graph_data['nodes']:
                    node_type = node.get('type', 'Unknown')
                    if node_type not in entity_types:
                        entity_types[node_type] = []
                    entity_types[node_type].append(node['id'])
                
                st.write("**Entity Types:**")
                for etype, entities in entity_types.items():
                    st.write(f"‚Ä¢ **{etype}:** {', '.join(entities[:3])}")
            
            with col2:
                st.metric("Relationships (Verbs)", len(graph_data['edges']))
                
                # Show relationship types
                rel_types = {}
                for edge in graph_data['edges']:
                    rel_type = edge.get('type', 'Unknown')
                    rel_types[rel_type] = rel_types.get(rel_type, 0) + 1
                
                st.write("**Relationship Types:**")
                for rtype, count in rel_types.items():
                    st.write(f"‚Ä¢ **{rtype}:** {count} connections")
            
            # Visualization
            st.markdown("### üåê Interactive Knowledge Graph")
            
            try:
                # Create pyvis graph
                net = create_pyvis_graph(graph_data)
                
                if net:
                    # Save to temp file and display
                    import uuid
                    temp_file = f"graph_{uuid.uuid4().hex[:8]}.html"
                    temp_path = os.path.join(tempfile.gettempdir(), temp_file)
                    
                    net.save_graph(temp_path)
                    
                    # Read and display
                    with open(temp_path, "r", encoding="utf-8") as f:
                        html_content = f.read()
                    
                    components.html(html_content, height=650)
                    
                    # Cleanup
                    try:
                        os.unlink(temp_path)
                    except:
                        pass
                else:
                    st.error("‚ùå Could not create visualization")
                    
            except Exception as e:
                st.error(f"Visualization error: {e}")
                st.info("üí° Make sure pyvis is installed: `pip install pyvis`")
            
            # Download option
            st.markdown("### üíæ Export")
            st.download_button(
                "üì• Download Graph JSON",
                json.dumps(graph_data, indent=2),
                file_name="knowledge_graph.json",
                mime="application/json"
            )
    
    else:
        # Instructions
        st.markdown("""
        ### üöÄ How it works:
        
        1. **Upload** your Excel file
        2. **AI analyzes** your data to find entities and relationships  
        3. **Interactive graph** shows hidden connections
        
        ### üí° What you'll discover:
        - **Entities (Nouns):** Systems, People, Technologies, Locations
        - **Relationships (Verbs):** Who manages what, what depends on what
        - **Hidden Connections:** Patterns not obvious from spreadsheet rows
        """)

if __name__ == "__main__":
    main()
