# =======================
# üì¶ IMPORTS
# =======================
import streamlit as st
import pandas as pd
import json
import base64
import re
import requests
from pyvis.network import Network
import tempfile
import os
import streamlit.components.v1 as components

# =======================
# üîß CONFIGURATION
# =======================
st.set_page_config(page_title="Knowledge Graph Builder", layout="wide")

# LLM Configuration
LLM_API_URL = "https://your-llm-endpoint.com/v1/chat/completions"
LLM_USERNAME = "your_username_here"  # Replace with actual username
LLM_PASSWORD = "your_password_here"  # Replace with actual password

# =======================
# üõ†Ô∏è UTILITY FUNCTIONS
# =======================
def get_basic_auth():
    """Create basic auth header"""
    creds = f"{LLM_USERNAME}:{LLM_PASSWORD}"
    return base64.b64encode(creds.encode()).decode()

def validate_graph(graph_data):
    """Validate graph structure"""
    return (isinstance(graph_data, dict) and 
            "nodes" in graph_data and "edges" in graph_data and
            isinstance(graph_data["nodes"], list) and 
            isinstance(graph_data["edges"], list) and
            len(graph_data["nodes"]) >= 3 and
            len(graph_data["edges"]) >= 2)

# =======================
# üìÑ DATA EXTRACTION FUNCTIONS
# =======================
def extract_data_from_excel(file):
    """Extract and structure data from Excel file"""
    try:
        df = pd.read_excel(file)
        
        # Show basic info
        st.write("**üìã File Info:**")
        st.write(f"- Rows: {len(df)}")
        st.write(f"- Columns: {len(df.columns)}")
        st.write(f"- Headers: {list(df.columns)}")
        
        # Show sample data
        st.write("**üìä Sample Data:**")
        st.dataframe(df.head())
        
        # Create structured summary for LLM
        summary = f"EXCEL DATA ANALYSIS:\n\n"
        summary += f"HEADERS: {list(df.columns)}\n\n"
        summary += f"TOTAL ROWS: {len(df)}\n\n"
        summary += f"SAMPLE DATA ROWS:\n"
        
        for i, row in df.head(10).iterrows():
            row_dict = row.to_dict()
            summary += f"Row {i+1}: {row_dict}\n"
        
        return summary
        
    except Exception as e:
        st.error(f"Error reading Excel file: {e}")
        return None

# =======================
# üß™ LLM TESTING FUNCTIONS
# =======================
def test_llm_connection():
    """Test LLM with a simple request to see what format it expects"""
    st.write("**üß™ Testing LLM with simple request...**")
    
    # Simple test prompt
    test_prompt = "Hello, please respond with: SUCCESS"
    
    # Try different payload formats that Llama APIs commonly use
    payload_formats = [
        # Format 1: Standard
        {
            "inputs": test_prompt,
            "parameters": {"temperature": 0.1, "max_new_tokens": 50}
        },
        # Format 2: Messages format
        {
            "messages": [{"role": "user", "content": test_prompt}],
            "temperature": 0.1,
            "max_tokens": 50
        },
        # Format 3: Prompt field
        {
            "prompt": test_prompt,
            "temperature": 0.1,
            "max_tokens": 50
        },
        # Format 4: Text field
        {
            "text": test_prompt,
            "parameters": {"temperature": 0.1, "max_new_tokens": 50}
        }
    ]
    
    headers = {
        "Authorization": f"Basic {get_basic_auth()}", 
        "Content-Type": "application/json"
    }
    
    for i, payload in enumerate(payload_formats, 1):
        try:
            st.write(f"**Testing Format {i}:** {list(payload.keys())}")
            response = requests.post(LLM_API_URL, headers=headers, json=payload, timeout=30)
            
            if response.status_code == 200:
                try:
                    resp_json = response.json()
                    st.write(f"‚úÖ Format {i} - Status 200:")
                    st.json(resp_json)
                    
                    # Check if we got actual content
                    content = ""
                    if isinstance(resp_json, dict):
                        for key in ["generated_text", "output", "response", "text", "content"]:
                            if key in resp_json:
                                content = resp_json[key]
                                break
                    elif isinstance(resp_json, list) and len(resp_json) > 0:
                        for key in ["generated_text", "output", "response", "text", "content"]:
                            if key in resp_json[0]:
                                content = resp_json[0][key]
                                break
                    
                    if content and "SUCCESS" in str(content):
                        st.success(f"üéâ Format {i} WORKS! Use this format.")
                        return i, payload_formats[i-1]
                    else:
                        st.warning(f"Format {i} returned empty or unexpected content")
                        
                except json.JSONDecodeError:
                    st.error(f"Format {i} - Invalid JSON response")
                    st.code(response.text[:200])
            else:
                st.error(f"Format {i} - Status {response.status_code}: {response.text[:100]}")
                
        except Exception as e:
            st.error(f"Format {i} - Error: {e}")
    
    return None, None

# =======================
# üéØ ENTITY EXTRACTION FUNCTIONS
# =======================
def extract_json_from_text(text):
    """Extract JSON from LLM response - ultra-simple approach"""
    
    st.write("**üîç Raw LLM Response (first 500 chars):**")
    st.code(text[:500])
    
    # Skip JSON entirely - just extract entities from text
    st.write("**üéØ Extracting entities directly from text (no JSON)...**")
    return extract_entities_from_text(text)

def extract_entities_from_text(text):
    """Extract entities directly from text without JSON parsing"""
    
    # Find all quoted strings (most reliable)
    quoted_entities = re.findall(r'"([^"]{2,30})"', text)
    quoted_entities += re.findall(r"'([^']{2,30})'", text)
    
    # Find capitalized words (likely entities)
    capitalized_words = re.findall(r'\b[A-Z][a-zA-Z\s]{2,25}\b', text)
    
    # Combine all potential entities
    all_entities = list(set(quoted_entities + capitalized_words))
    
    st.write(f"**Found {len(all_entities)} potential entities:**")
    for entity in all_entities[:10]:
        st.write(f"- {entity}")
    
    if len(all_entities) < 3:
        st.warning("Not enough entities found, creating basic demo")
        return create_minimal_demo_graph()
    
    # Create nodes from entities
    nodes = []
    for i, entity in enumerate(all_entities[:8]):  # Limit to 8 nodes
        entity = entity.strip()
        
        # Determine type based on keywords
        if any(word in entity.lower() for word in ['system', 'app', 'portal', 'management']):
            node_type = "Application"
        elif any(word in entity.lower() for word in ['database', 'db', 'data']):
            node_type = "Database"
        elif any(word in entity.lower() for word in ['server', 'host', 'machine']):
            node_type = "Server"
        elif any(word in entity.lower() for word in ['windows', 'linux', 'oracle', 'mysql']):
            node_type = "Technology"
        elif len(entity.split()) == 2 and entity.istitle():
            node_type = "Person"  # Likely a person name
        else:
            node_type = "Component"
        
        nodes.append({"id": entity, "type": node_type})
    
    # Create simple connecting edges
    edges = []
    for i in range(len(nodes) - 1):
        edges.append({
            "source": nodes[i]['id'],
            "target": nodes[i + 1]['id'],
            "type": "CONNECTS_TO"
        })
    
    # Add some management relationships
    people = [n for n in nodes if n['type'] == 'Person']
    systems = [n for n in nodes if n['type'] in ['Application', 'Database', 'Server']]
    
    for person in people[:2]:  # First 2 people
        for system in systems[:2]:  # First 2 systems
            edges.append({
                "source": person['id'],
                "target": system['id'],
                "type": "MANAGES"
            })
    
    result = {"nodes": nodes, "edges": edges}
    
    st.success(f"‚úÖ Created graph: {len(nodes)} entities, {len(edges)} relationships")
    
    # Show what was created
    st.write("**Created Entities:**")
    for node in nodes[:5]:
        st.write(f"- {node['id']} ({node['type']})")
    
    return result

def create_minimal_demo_graph():
    """Create absolute minimal graph when everything else fails"""
    st.write("**üîß Creating minimal demo graph...**")
    
    nodes = [
        {"id": "System A", "type": "Application"},
        {"id": "Database B", "type": "Database"},
        {"id": "Server C", "type": "Server"},
        {"id": "Admin User", "type": "Person"}
    ]
    
    edges = [
        {"source": "System A", "target": "Database B", "type": "USES"},
        {"source": "System A", "target": "Server C", "type": "RUNS_ON"},
        {"source": "Admin User", "target": "System A", "type": "MANAGES"}
    ]
    
    return {"nodes": nodes, "edges": edges}

# =======================
# ü§ñ LLM KNOWLEDGE GRAPH FUNCTIONS
# =======================
def create_knowledge_graph_with_llm(data_summary):
    """Use LLM to extract knowledge graph - with format testing and simplified prompt"""
    
    # Test LLM first
    working_format_num, working_format = test_llm_connection()
    
    if not working_format:
        st.error("‚ùå None of the common API formats worked. Check your LLM API documentation.")
        return None
    
    st.success(f"‚úÖ Using working format {working_format_num}")
    
    # SIMPLIFIED prompt that works better with Llama
    prompt = f"""Extract entities and relationships from this business data. Return JSON only.

Data:
{data_summary[:1000]}  

Create a knowledge graph with:
- Entities: People, Systems, Technologies, Locations
- Relationships: MANAGES, USES, DEPENDS_ON, LOCATED_IN

Format:
{{"nodes": [{{"id": "EntityName", "type": "EntityType"}}], "edges": [{{"source": "Source", "target": "Target", "type": "RELATIONSHIP"}}]}}

JSON:"""

    # Build payload using working format
    payload = {
        "inputs": prompt,
        "parameters": {"temperature": 0.1, "max_new_tokens": 600}  # Reduced tokens
    }
    
    try:
        headers = {
            "Authorization": f"Basic {get_basic_auth()}", 
            "Content-Type": "application/json"
        }
        
        st.write(f"**üìù Simplified prompt length:** {len(prompt)} characters")
        
        with st.spinner("üß† Creating knowledge graph with simplified prompt..."):
            response = requests.post(LLM_API_URL, headers=headers, json=payload, timeout=45)
        
        if response.status_code == 200:
            resp_json = response.json()
            
            # Extract content using the same method that worked in test
            content = ""
            if isinstance(resp_json, dict):
                for key in ["generated_text", "output", "response", "text", "content"]:
                    if key in resp_json and resp_json[key]:
                        content = resp_json[key]
                        break
            elif isinstance(resp_json, list) and len(resp_json) > 0:
                for key in ["generated_text", "output", "response", "text", "content"]:
                    if key in resp_json[0] and resp_json[0][key]:
                        content = resp_json[0][key]
                        break
            
            if not content:
                st.error("‚ùå LLM returned empty content even with simplified prompt")
                st.write("**Trying even shorter prompt...**")
                return try_minimal_prompt(data_summary)
            
            # Clean response
            if "JSON:" in content:
                content = content.split("JSON:")[-1].strip()
            
            st.write("**ü§ñ LLM Response:**")
            st.code(content[:300] + "..." if len(content) > 300 else content)
            
            # Extract JSON from response
            graph_data = extract_json_from_text(content)
            
            if graph_data and validate_graph(graph_data):
                st.success(f"‚úÖ Knowledge Graph Created: {len(graph_data['nodes'])} entities, {len(graph_data['edges'])} relationships")
                return graph_data
            else:
                st.warning("‚ö†Ô∏è Could not extract valid graph, trying minimal prompt...")
                return try_minimal_prompt(data_summary)
        else:
            st.error(f"‚ùå LLM API Error: {response.status_code} - {response.text}")
            return None
            
    except Exception as e:
        st.error(f"‚ùå Error calling LLM: {e}")
        return None

def try_minimal_prompt(data_summary):
    """Last resort: ultra-minimal prompt"""
    st.write("**üî¨ Trying ultra-minimal prompt...**")
    
    # Extract just the first few rows of data
    lines = data_summary.split('\n')
    sample_data = '\n'.join(lines[:10])  # Just first 10 lines
    
    minimal_prompt = f"""Make a simple graph from this data:

{sample_data}

Return this format:
{{"nodes":[{{"id":"Name","type":"Type"}}],"edges":[{{"source":"A","target":"B","type":"USES"}}]}}"""

    payload = {
        "inputs": minimal_prompt,
        "parameters": {"temperature": 0.1, "max_new_tokens": 300}
    }
    
    try:
        headers = {
            "Authorization": f"Basic {get_basic_auth()}", 
            "Content-Type": "application/json"
        }
        
        st.write(f"**üìù Minimal prompt length:** {len(minimal_prompt)} characters")
        
        response = requests.post(LLM_API_URL, headers=headers, json=payload, timeout=30)
        
        if response.status_code == 200:
            resp_json = response.json()
            
            content = ""
            if isinstance(resp_json, dict) and "generated_text" in resp_json:
                content = resp_json["generated_text"]
            elif isinstance(resp_json, list) and len(resp_json) > 0 and "generated_text" in resp_json[0]:
                content = resp_json[0]["generated_text"]
            
            if content:
                st.write("**ü§ñ Minimal Response:**")
                st.code(content)
                
                # Try to extract JSON
                graph_data = extract_json_from_text(content)
                
                if graph_data and validate_graph(graph_data):
                    st.success(f"‚úÖ Minimal Graph Created: {len(graph_data['nodes'])} entities, {len(graph_data['edges'])} relationships")
                    return graph_data
                else:
                    st.error("‚ùå Even minimal prompt failed to generate valid graph")
                    return create_basic_fallback_from_data(data_summary)
            else:
                st.error("‚ùå Minimal prompt also returned empty")
                return create_basic_fallback_from_data(data_summary)
        else:
            st.error(f"‚ùå Minimal prompt failed: {response.status_code}")
            return create_basic_fallback_from_data(data_summary)
            
    except Exception as e:
        st.error(f"‚ùå Minimal prompt error: {e}")
        return create_basic_fallback_from_data(data_summary)

def create_basic_fallback_from_data(data_summary):
    """Create a basic graph directly from the data without LLM"""
    st.write("**üõ†Ô∏è Creating basic graph from data patterns...**")
    
    nodes = []
    edges = []
    
    # Simple pattern matching from the data
    lines = data_summary.split('\n')
    
    # Look for sample data rows
    for line in lines:
        if line.startswith("Row") and ":" in line:
            try:
                row_str = line.split(": ", 1)[1]
                row_data = eval(row_str)
                
                # Extract entities from row
                for key, value in row_data.items():
                    if value and len(str(value).strip()) > 2:
                        value_clean = str(value).strip()
                        
                        # Determine entity type from column name
                        if any(word in key.lower() for word in ['system', 'application', 'app']):
                            nodes.append({"id": value_clean, "type": "Application"})
                        elif any(word in key.lower() for word in ['person', 'owner', 'manager', 'user']):
                            nodes.append({"id": value_clean, "type": "Person"})
                        elif any(word in key.lower() for word in ['database', 'db', 'data']):
                            nodes.append({"id": value_clean, "type": "Database"})
                        elif any(word in key.lower() for word in ['server', 'host', 'machine']):
                            nodes.append({"id": value_clean, "type": "Server"})
                        elif any(word in key.lower() for word in ['location', 'site', 'datacenter']):
                            nodes.append({"id": value_clean, "type": "Location"})
                        else:
                            nodes.append({"id": value_clean, "type": "Component"})
                
            except:
                continue
    
    # Remove duplicates
    unique_nodes = []
    seen_ids = set()
    for node in nodes:
        if node['id'] not in seen_ids:
            unique_nodes.append(node)
            seen_ids.add(node['id'])
    
    nodes = unique_nodes[:10]  # Limit to 10 nodes
    
    # Create simple relationships
    for i in range(len(nodes) - 1):
        edges.append({
            "source": nodes[i]['id'],
            "target": nodes[i + 1]['id'],
            "type": "CONNECTS_TO"
        })
    
    if len(nodes) >= 3 and len(edges) >= 2:
        st.success(f"‚úÖ Basic graph created: {len(nodes)} entities, {len(edges)} relationships")
        return {"nodes": nodes, "edges": edges}
    else:
        st.error("‚ùå Could not create graph from data")
        return None

# =======================
# üé® VISUALIZATION FUNCTIONS
# =======================
def create_pyvis_graph(graph_data):
    """Create interactive pyvis visualization with extra safety"""
    
    # Validate data first
    if not graph_data or 'nodes' not in graph_data or 'edges' not in graph_data:
        st.error("‚ùå Invalid graph data structure")
        return None
    
    nodes = graph_data['nodes']
    edges = graph_data['edges']
    
    if len(nodes) < 2:
        st.error("‚ùå Need at least 2 nodes for visualization")
        return None
    
    try:
        net = Network(
            height="600px", 
            width="100%", 
            directed=True,
            bgcolor="#f8f9fa"
        )
        
        # Color scheme
        type_colors = {
            'Application': '#FF6B6B',
            'Database': '#4ECDC4', 
            'Server': '#45B7D1',
            'Person': '#FFA07A',
            'Location': '#98D8C8',
            'Technology': '#DDA0DD',
            'Component': '#D3D3D3'
        }
        
        # Add nodes with validation
        valid_node_ids = set()
        for node in nodes:
            if isinstance(node, dict) and 'id' in node:
                node_id = str(node['id']).strip()
                node_type = str(node.get('type', 'Component'))
                
                if node_id and len(node_id) > 0:
                    color = type_colors.get(node_type, '#D3D3D3')
                    
                    net.add_node(
                        node_id,
                        label=node_id[:20],  # Limit label length
                        color=color,
                        title=f"Type: {node_type}",
                        size=20
                    )
                    valid_node_ids.add(node_id)
        
        st.write(f"**‚úÖ Added {len(valid_node_ids)} nodes to visualization**")
        
        # Add edges with strict validation
        valid_edges = 0
        for edge in edges:
            if isinstance(edge, dict) and 'source' in edge and 'target' in edge:
                source = str(edge['source']).strip()
                target = str(edge['target']).strip()
                edge_type = str(edge.get('type', 'CONNECTS_TO'))
                
                if source in valid_node_ids and target in valid_node_ids and source != target:
                    net.add_edge(
                        source,
                        target,
                        label=edge_type[:15],  # Limit label length
                        title=f"{source} {edge_type} {target}"
                    )
                    valid_edges += 1
                else:
                    st.warning(f"‚ö†Ô∏è Skipping invalid edge: {source} ‚Üí {target}")
        
        st.write(f"**‚úÖ Added {valid_edges} edges to visualization**")
        
        if valid_edges == 0:
            st.warning("‚ö†Ô∏è No valid edges found, adding basic connections")
            # Add basic connections between consecutive nodes
            node_list = list(valid_node_ids)
            for i in range(len(node_list) - 1):
                net.add_edge(node_list[i], node_list[i + 1], label="CONNECTS_TO")
        
        # Simple physics
        net.set_options("""
        var options = {
          "physics": {"enabled": true, "stabilization": {"iterations": 50}}
        }
        """)
        
        return net
        
    except Exception as e:
        st.error(f"‚ùå Pyvis error: {e}")
        st.info("üí° Try restarting Streamlit or check pyvis installation")
        return None

# =======================
# üñºÔ∏è MAIN APPLICATION
# =======================
def main():
    # Header
    st.title("üîó Knowledge Graph Builder")
    st.markdown("Upload an Excel file and let AI create a knowledge graph showing hidden connections!")
    
    # LLM Status
    llm_configured = LLM_USERNAME != "your_username_here"
    status = "üü¢ Connected" if llm_configured else "üî¥ Configure LLM credentials"
    st.sidebar.markdown(f"**LLM Status:** {status}")
    
    if not llm_configured:
        st.sidebar.warning("Update LLM_USERNAME and LLM_PASSWORD in the code")
    
    # File upload
    uploaded_file = st.file_uploader(
        "üìÅ Upload Excel File", 
        type=['xlsx', 'xls'],
        help="Upload an Excel file with your data"
    )
    
    if uploaded_file:
        # Extract data
        data_summary = extract_data_from_excel(uploaded_file)
        
        if data_summary:
            # Create knowledge graph
            st.markdown("---")
            st.markdown("### üß† Creating Knowledge Graph")
            
            if llm_configured:
                graph_data = create_knowledge_graph_with_llm(data_summary)
            else:
                st.error("‚ö†Ô∏è Configure LLM credentials to create knowledge graph")
                return
            
            if not graph_data:
                st.error("‚ùå Failed to create knowledge graph")
                return
            
            # Show graph details
            st.markdown("### üìä Graph Details")
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("Entities (Nouns)", len(graph_data['nodes']))
                
                # Show entity types
                entity_types = {}
                for node in graph_data['nodes']:
                    node_type = node.get('type', 'Unknown')
                    if node_type not in entity_types:
                        entity_types[node_type] = []
                    entity_types[node_type].append(node['id'])
                
                st.write("**Entity Types:**")
                for etype, entities in entity_types.items():
                    st.write(f"‚Ä¢ **{etype}:** {', '.join(entities[:3])}")
            
            with col2:
                st.metric("Relationships (Verbs)", len(graph_data['edges']))
                
                # Show relationship types
                rel_types = {}
                for edge in graph_data['edges']:
                    rel_type = edge.get('type', 'Unknown')
                    rel_types[rel_type] = rel_types.get(rel_type, 0) + 1
                
                st.write("**Relationship Types:**")
                for rtype, count in rel_types.items():
                    st.write(f"‚Ä¢ **{rtype}:** {count} connections")
            
            # Visualization
            st.markdown("### üåê Interactive Knowledge Graph")
            
            try:
                # Create pyvis graph
                net = create_pyvis_graph(graph_data)
                
                if net:
                    # Save to temp file and display
                    import uuid
                    temp_file = f"graph_{uuid.uuid4().hex[:8]}.html"
                    temp_path = os.path.join(tempfile.gettempdir(), temp_file)
                    
                    net.save_graph(temp_path)
                    
                    # Read and display
                    with open(temp_path, "r", encoding="utf-8") as f:
                        html_content = f.read()
                    
                    components.html(html_content, height=650)
                    
                    # Cleanup
                    try:
                        os.unlink(temp_path)
                    except:
                        pass
                else:
                    st.error("‚ùå Could not create visualization")
                    
            except Exception as e:
                st.error(f"Visualization error: {e}")
                st.info("üí° Make sure pyvis is installed: `pip install pyvis`")
            
            # Download option
            st.markdown("### üíæ Export")
            st.download_button(
                "üì• Download Graph JSON",
                json.dumps(graph_data, indent=2),
                file_name="knowledge_graph.json",
                mime="application/json"
            )
    
    else:
        # Instructions
        st.markdown("""
        ### üöÄ How it works:
        
        1. **Upload** your Excel file
        2. **AI analyzes** your data to find entities and relationships  
        3. **Interactive graph** shows hidden connections
        
        ### üí° What you'll discover:
        - **Entities (Nouns):** Systems, People, Technologies, Locations
        - **Relationships (Verbs):** Who manages what, what depends on what
        - **Hidden Connections:** Patterns not obvious from spreadsheet rows
        """)

if __name__ == "__main__":
    main()
